A python cli application, built using the "click" framework. It takes prompts 
stored in the local filesystem and produces code files, stored along with the prompts.

The prompt files have ".prompt" suffix. For example, a prompt to produce example.py 
will be stored in the example.py.prompt file.

Prompt files may contain @raw(filename) and @prompt(filename) directives. Example:

```
  @raw(path/to/some/file.py)
  Some text @prompt(path/to/another/file.py.prompt) more text.
  Even a relative @raw(../filename.txt) path is possible. The path is 
  relative to the file that contains the directive.
```
The directives may be inside the text. Use regular expressions to find them.
The application shall replace these directives with the contents of the specified file.
If the file included using @prompt directive itself contains @prompt directives, they should be expanded as well.
The user may avoid exansion by passing the --skip-directives parameter.

To produce code from the prompt please use llm_invoke function from the .models module in the same folder.
The function takes three params:
- provider, which can be either 'bedrock' or 'anthropic', the default being 'bedrock'. Let the user specify the needed
provider using --provider parameter.
- model, the default being 'anthropic.claude-3-5-sonnet-20240620-v1:0'. Let the user specify the needed model
using the --model parameter.
- messages, an array of chat messages to pass to the model
The function returns LLM's answer.

The user may ask to process the dependencies using --dependencies option. In this case, when including 
a file using @raw directive, the script should check if there's a corresponding .prompt file and process it first.
An error should be shown to the user whenever a circular dependency is found.

The user may ask to process a folder in a recursive manner using --recursive option. In this case, instead of
passing a file name, the user provides a folder name. All .prompt files in this folder and its subfolders should
be ordered so that dependencies are processed first. An error should be shown to the user whenever a circular 
dependency is found. Skip any folders that start with a dot, such as '.aws-sam'.

Use these system instructions when invoking the LLM:
<instructions>Output just the file content, nothing else. Do not print any 
introductory text before the code. Do not enclose the code in triple quotes. 
Include a comment in the code
saying that this file was produced by AI from a prompt and shouldn't 
be edited directly, unless generating json or other file formats
that don't support comments.</instructions>

Also provide a one-shot example, such as 
<user>Hello world in python</user>
<assistant>print('Hello world')</assistant>

Name the entry point function as 'main'.

System message must be at beginning of message list.

Print the name of each file being processed before starting the processing.
